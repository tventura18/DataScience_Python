{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cacf7f4360d6d53c622742f64048f72c",
     "grade": false,
     "grade_id": "cell-8a754c8ce8a16eeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices. **This Series should be sorted by a tie-break sort in the format of (\"extracted date\", \"original row number\").**\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b47ce38a503bfb1f113580f394d8667",
     "grade": false,
     "grade_id": "cell-28048f36edc32946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('assets/dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e58e227860ae4b02d6bdddd81506787",
     "grade": false,
     "grade_id": "cell-d6f35a51303ed6ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text\n",
      "0         03/25/93 Total time of visit (in minutes):\\n\n",
      "1                       6/18/85 Primary Care Doctor:\\n\n",
      "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
      "3                7 on 9/27/75 Audit C Score Current:\\n\n",
      "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
      "..                                                 ...\n",
      "495  1979 Family Psych History: Family History of S...\n",
      "496  therapist and friend died in ~2006 Parental/Ca...\n",
      "497                       2008 partial thyroidectomy\\n\n",
      "498  sPt describes a history of sexual abuse as a c...\n",
      "499  . In 1980, patient was living in Naples and de...\n",
      "\n",
      "[500 rows x 1 columns]\n",
      "0        9\n",
      "1       84\n",
      "2        2\n",
      "3       53\n",
      "4       28\n",
      "      ... \n",
      "495    427\n",
      "496    141\n",
      "497    186\n",
      "498    161\n",
      "499    413\n",
      "Name: original_index, Length: 500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    order = None\n",
    "    # YOUR CODE HERE\n",
    "    import re\n",
    "    try:\n",
    "        # Read file into a Pandas Series\n",
    "        with open('assets/dates.txt', 'r') as file:\n",
    "            df = pd.Series(file.readlines())  # Directly read all lines\n",
    "        ##print(df.columns)\n",
    "        ##df_dates = df.copy()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df_dates = pd.DataFrame(df.copy(), columns=[\"text\"])\n",
    "        print(df_dates)\n",
    "        \n",
    "        # Define date patterns (regex)\n",
    "        date_patterns = [\n",
    "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[.,]?\\s*\\d{4})',\n",
    "            r'(\\d{1,2}/\\d{1,2}/\\d{2,4})',\n",
    "            r'\\b(?!\\d{3}-\\d{3}-\\d{4}\\b)(\\d{1,2}-\\d{1,2}-\\d{2,4})',\n",
    "            r'(?<!\\d)(?:[a-zA-Z])?(\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4})(?!-\\d{4})',\n",
    "            r'(?<!\\d)(?:[a-zA-Z])?(\\d{1,2}/\\d{2,4})(?!-\\d{4})',\n",
    "            r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[.,]?\\s*\\d{0,2},?\\s*\\d{4})',\n",
    "            r'(\\d{1,2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4})',\n",
    "            r'(\\d{1,2}/\\d{4})',\n",
    "            r'((?:19\\d{2}|20[0-2]\\d|202[0-4]))'\n",
    "        ]\n",
    "\n",
    "        month_corrections = {\n",
    "        \"Janaury\": \"January\",\n",
    "        \"Decemeber\": \"December\",   # Example of a partial misspelling\n",
    "        } \n",
    "        \n",
    "        # Combine all patterns into one\n",
    "        combined_pattern = \"|\".join(date_patterns)\n",
    "\n",
    "        # Extract dates and the line they were found in\n",
    "        \n",
    "        df_dates['extracted_date'] = df_dates['text'].apply(\n",
    "            lambda text: next(\n",
    "            (group for m in re.finditer(combined_pattern, text) for group in m.groups() if group),\n",
    "            None\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        df_dates['parsed_date'] = df_dates['extracted_date'].apply(\n",
    "            lambda x: ' '.join([month_corrections.get(word, word) for word in x.split()]) if pd.notnull(x) else x\n",
    "        )\n",
    "        \n",
    "        \n",
    "        pattern = re.compile(\n",
    "            r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/](\\d{2,4}))\\b'            # Group 1: MM/DD/YY or MM/DD/YYYY\n",
    "            r'|\\b(?:\\d{1,2}[-/](\\d{2,4}))\\b'                      # Group 2: MM/YYYY or MM/YY\n",
    "            ##r'\\b(?:[^\\d]?(\\d{1,2})[-/](\\d{2,4}))\\b' \n",
    "            # Group 2: MM/YYYY or MM/YY\n",
    "            r'|\\b(19\\d{2}|20[0-2][0-9]|202[0-4])\\b'               # Group 3: just a year\n",
    "            r'|\\b(\\d{1,2}) ((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*) (\\d{4})\\b'\n",
    "            # Groups:# 4 = day (e.g., \"12\") # 5 = month name (e.g., \"Feb\") # 6 = year (e.g., \"2002\")\n",
    "            r'|\\b((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[.,]?)\\s+(\\d{0,2})[.,]?\\s*(\\d{4})\\b'  \n",
    "            # Groups 7-9: Jan 1, 2021\n",
    "        )\n",
    "\n",
    "        df_dates['year'] = df_dates['parsed_date'].apply(\n",
    "        lambda x: \n",
    "        (\n",
    "            (\n",
    "                m := pattern.search(str(x)))\n",
    "                and \n",
    "                    (\n",
    "                        (\n",
    "                            #y := next((g for g in m.groups()[::1] if g and g.isdigit()), None))\n",
    "                            y := next((g for g in reversed(m.groups()) if g and re.fullmatch(r'\\d{2,4}', g)), None))\n",
    "                and \n",
    "                    (\n",
    "                        '19' + y if len(y) == 2 and int(y) > 24 else\n",
    "                            '20' + y if len(y) == 2 else\n",
    "                                y\n",
    "                    )\n",
    "                )\n",
    "            ) \n",
    "            if pattern.search(str(x)) else ''\n",
    "        )\n",
    "        \n",
    "        # Extract month inline\n",
    "        df_dates['month'] = df_dates['parsed_date'].apply(\n",
    "        lambda x: \n",
    "        (\n",
    "            (\n",
    "                m := pattern.search(str(x))) and (\n",
    "                (\n",
    "                    (lambda p: p[0] if p and p[0].isdigit() else '')(\n",
    "                        re.split(r'[-/]', str(x)) if re.match(r'^\\d{1,2}[-/]', str(x)) else []\n",
    "                    )\n",
    "                )\n",
    "            or (m.group(5) if m.group(5) else '')\n",
    "            or (m.group(7) if m.group(7) else '')\n",
    "            )\n",
    "            ) or '01'\n",
    "        )\n",
    "        \n",
    "        # Extract the day \n",
    "        df_dates['day'] = df_dates['parsed_date'].apply(\n",
    "        lambda x: (\n",
    "        (m := pattern.search(str(x))) and (\n",
    "            # Only if date has 3 parts (e.g., MM/DD/YYYY or DD-MM-YYYY)\n",
    "            (lambda p: p[1].zfill(2) if len(p) == 3 and p[1] and p[1].isdigit() else '')(\n",
    "                re.split(r'[-/]', str(x)) if re.match(r'^\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}$', str(x).zfill(2)) else []\n",
    "            )\n",
    "            # From \"12 Feb 2002\"\n",
    "            or (m.group(4).zfill(2) if m.lastindex and m.lastindex >= 4 and m.group(4) and m.group(4).isdigit() else '')\n",
    "            # From \"Feb 12, 2002\"\n",
    "            or (m.group(8).zfill(2) if m.lastindex and m.lastindex >= 8 and m.group(8) and m.group(8).isdigit() else '')\n",
    "        )\n",
    "            ) or '01'\n",
    "        )\n",
    "\n",
    "        \n",
    "        df_dates['month'] = df_dates['month'].apply(\n",
    "        lambda m: (\n",
    "        str(m).zfill(2) if str(m).isdigit() and 1 <= int(m) <= 12 else (\n",
    "            (match := re.search(r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*', str(m), re.IGNORECASE))\n",
    "            and {\n",
    "                'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05',\n",
    "                'jun': '06', 'jul': '07', 'aug': '08', 'sep': '09',\n",
    "                'oct': '10', 'nov': '11', 'dec': '12'\n",
    "            }.get(match.group(1).lower(), '')\n",
    "        )\n",
    "            ) or ''\n",
    "        )        \n",
    "        \n",
    "        df_dates['normalized_date'] = df_dates['year'] + '-' + df_dates['month'] + '-' + df_dates['day']\n",
    "    \n",
    "        df_dates['original_index']= df_dates.index \n",
    "        \n",
    "        sorted_df_dates = df_dates.sort_values(by=['normalized_date', 'original_index']).reset_index(drop=True)\n",
    "        \n",
    "        sorted_df_dates['sorted_index']= range(len(df_dates))\n",
    "        \n",
    "        \n",
    "        print(sorted_df_dates['original_index'])\n",
    "        #df_dates.to_csv('output.csv', index=True, encoding='utf-8', quoting=1)\n",
    "        sorted_df_dates.to_csv('output.csv', index=True, encoding='utf-8', quoting=1)\n",
    "\n",
    "        ##print(sorted_df_dates['original_index'].apply(type))\n",
    "        return sorted_df_dates['original_index']\n",
    "    except FileNotFoundError:\n",
    "                print(\"Error: File 'assets/dates.txt' not found.\")\n",
    "    return None  # Return None if file is missing\n",
    "    raise NotImplementedError()\n",
    "    ##return order # Your answer here\n",
    "s_test = date_sorter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0843c1f0ad2aaa45fa9ac4012f1aa43",
     "grade": true,
     "grade_id": "cell-373f878879c00996",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2f5bb6bab79c07a81ec366c46c4d49",
     "grade": true,
     "grade_id": "cell-0ebae76e6cd794be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "0      <class 'str'>\n",
      "1      <class 'str'>\n",
      "2      <class 'str'>\n",
      "3      <class 'str'>\n",
      "4      <class 'str'>\n",
      "           ...      \n",
      "495    <class 'str'>\n",
      "496    <class 'str'>\n",
      "497    <class 'str'>\n",
      "498    <class 'str'>\n",
      "499    <class 'str'>\n",
      "Length: 500, dtype: object\n",
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "       ... \n",
      "495    True\n",
      "496    True\n",
      "497    True\n",
      "498    True\n",
      "499    True\n",
      "Length: 500, dtype: bool\n",
      "True\n",
      "Passed df modification check\n",
      "                                                  text\n",
      "0         03/25/93 Total time of visit (in minutes):\\n\n",
      "1                       6/18/85 Primary Care Doctor:\\n\n",
      "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
      "3                7 on 9/27/75 Audit C Score Current:\\n\n",
      "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
      "..                                                 ...\n",
      "495  1979 Family Psych History: Family History of S...\n",
      "496  therapist and friend died in ~2006 Parental/Ca...\n",
      "497                       2008 partial thyroidectomy\\n\n",
      "498  sPt describes a history of sexual abuse as a c...\n",
      "499  . In 1980, patient was living in Naples and de...\n",
      "\n",
      "[500 rows x 1 columns]\n",
      "0        9\n",
      "1       84\n",
      "2        2\n",
      "3       53\n",
      "4       28\n",
      "      ... \n",
      "495    427\n",
      "496    141\n",
      "497    186\n",
      "498    161\n",
      "499    413\n",
      "Name: original_index, Length: 500, dtype: int64\n",
      "Passed repeatability check\n",
      "                                                  text\n",
      "0         03/25/93 Total time of visit (in minutes):\\n\n",
      "1                       6/18/85 Primary Care Doctor:\\n\n",
      "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
      "3                7 on 9/27/75 Audit C Score Current:\\n\n",
      "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
      "..                                                 ...\n",
      "495  1979 Family Psych History: Family History of S...\n",
      "496  therapist and friend died in ~2006 Parental/Ca...\n",
      "497                       2008 partial thyroidectomy\\n\n",
      "498  sPt describes a history of sexual abuse as a c...\n",
      "499  . In 1980, patient was living in Naples and de...\n",
      "\n",
      "[500 rows x 1 columns]\n",
      "0        9\n",
      "1       84\n",
      "2        2\n",
      "3       53\n",
      "4       28\n",
      "      ... \n",
      "495    427\n",
      "496    141\n",
      "497    186\n",
      "498    161\n",
      "499    413\n",
      "Name: original_index, Length: 500, dtype: int64\n",
      "Passed index check\n",
      "Passed secondary sort sample check\n"
     ]
    }
   ],
   "source": [
    "def run_df_modified_check():\n",
    "    \n",
    "    #Check if df appears to be modified.\n",
    "    \n",
    "    print(type(df) == pd.Series)\n",
    "    print(df.index == pd.RangeIndex(start=0, stop=500, step=1))\n",
    "    print(df.apply(type))\n",
    "    print(df.apply(type) == str)\n",
    "    #print(s_test.apply(type) == str)\n",
    "    print(df.astype(str).str.len().min() >= 6)\n",
    "    \n",
    "    #print(s_test.astype(str).str[5].dropna().apply(ord).sum() == 38354)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        assert type(df) == pd.Series\n",
    "        assert (df.index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "        assert (df.apply(type) == str).all()\n",
    "        assert df.str.len().min() >= 6\n",
    "        assert df.str[5].apply(ord).sum() == 38354\n",
    "        print(\"Passed df modification check\")\n",
    "    except:\n",
    "        print(\"Failed df modification check\")\n",
    "\n",
    "run_df_modified_check()\n",
    "\n",
    "# check if running the code twice produces the same result\n",
    "try:\n",
    "    assert (date_sorter() == s_test).all()\n",
    "    print(\"Passed repeatability check\")\n",
    "except:\n",
    "   print(\"Failed repeatability check\")\n",
    "\n",
    "# check if the result has the expected index\n",
    "try:\n",
    "    # assert type(date_sorter().index) == pd.RangeIndex\n",
    "    # assert (date_sorter().index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "    assert list(date_sorter().index) == list(range(500))\n",
    "    print(\"Passed index check\")\n",
    "except:\n",
    "    print(\"Failed index check\")\n",
    "# check the tie-break sort for a sample of records where some have the same date\n",
    "# note that this only tests a sample and does not check the entire answer\n",
    "try:\n",
    "    test_indices = [335, 415, 323, 405, 370, 382, 303, 488, 283,\n",
    "                    395, 318, 369, 493, 252, 314, 410, 490]\n",
    "    answer_lkp = {original_index:answer_index for\n",
    "                  answer_index, original_index in s_test.to_dict().items()}\n",
    "    i_test = [answer_lkp[i] for i in test_indices]\n",
    "    assert sorted(i_test) == i_test\n",
    "    print(\"Passed secondary sort sample check\")\n",
    "except:\n",
    "    print(\"Failed secondary sort sample check\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9  84   2  53  28 474 153  13 129  98]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[   9  168    6  212  140 2844 1071  104 1161  980]\n",
      "[  495  4620   110  2915  1540 26070  8415   715  7095  5390]\n",
      "\n",
      "Block 0:\n",
      "  Values: [  9  84   2  53  28 474 153  13 129  98]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [   9  168    6  212  140 2844 1071  104 1161  980]\n",
      "  Checksum: 6695\n",
      "\n",
      "Block 1:\n",
      "  Values: [111 225  31 171 191 486 335 415  36 323]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 111  450   93  684  955 2916 2345 3320  324 3230]\n",
      "  Checksum: 14428\n",
      "\n",
      "Block 2:\n",
      "  Values: [405 422 375 380 345  57 481 436 104 299]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 405  844 1125 1520 1725  342 3367 3488  936 2990]\n",
      "  Checksum: 16742\n",
      "\n",
      "Block 3:\n",
      "  Values: [162 154 402  95  73 108 156 332 182  82]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 162  308 1206  380  365  648 1092 2656 1638  820]\n",
      "  Checksum: 9275\n",
      "\n",
      "Block 4:\n",
      "  Values: [351 278 214 155 223 473  49 317  11 319]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 351  556  642  620 1115 2838  343 2536   99 3190]\n",
      "  Checksum: 12290\n",
      "\n",
      "Block 5:\n",
      "  Values: [ 40 418 165 370 382   3  50 363 219 465]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  40  836  495 1480 1910   18  350 2904 1971 4650]\n",
      "  Checksum: 14654\n",
      "\n",
      "Block 6:\n",
      "  Values: [237  23 342 204 258 315  27  93  17 303]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 237   46 1026  816 1290 1890  189  744  153 3030]\n",
      "  Checksum: 9421\n",
      "\n",
      "Block 7:\n",
      "  Values: [488 283 395 309 419 123  19 117 232  72]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 488  566 1185 1236 2095  738  133  936 2088  720]\n",
      "  Checksum: 10185\n",
      "\n",
      "Block 8:\n",
      "  Values: [189 318 369 493 239 148 105 336   6 200]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 189  636 1107 1972 1195  888  735 2688   54 2000]\n",
      "  Checksum: 11464\n",
      "\n",
      "Block 9:\n",
      "  Values: [ 81  65 434 164 313 378 495 424 398   5]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  81  130 1302  656 1565 2268 3465 3392 3582   50]\n",
      "  Checksum: 16491\n",
      "\n",
      "Block 10:\n",
      "  Values: [254 296  75 167  21 259 499 347 150  78]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 254  592  225  668  105 1554 3493 2776 1350  780]\n",
      "  Checksum: 11797\n",
      "\n",
      "Block 11:\n",
      "  Values: [340 441 267 361 221 466  39 134 197 355]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 340  882  801 1444 1105 2796  273 1072 1773 3550]\n",
      "  Checksum: 14036\n",
      "\n",
      "Block 12:\n",
      "  Values: [430  80 246 444  85 215 263  74 403 458]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 430  160  738 1776  425 1290 1841  592 3627 4580]\n",
      "  Checksum: 15459\n",
      "\n",
      "Block 13:\n",
      "  Values: [ 16  25 127 454  70  44  59 103 112 429]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  16   50  381 1816  350  264  413  824 1008 4290]\n",
      "  Checksum: 9412\n",
      "\n",
      "Block 14:\n",
      "  Values: [ 88 179 358 470 205 294 397 137 295  35]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  88  358 1074 1880 1025 1764 2779 1096 2655  350]\n",
      "  Checksum: 13069\n",
      "\n",
      "Block 15:\n",
      "  Values: [438 247 209  61 107 285 175  99 455  24]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 438  494  627  244  535 1710 1225  792 4095  240]\n",
      "  Checksum: 10400\n",
      "\n",
      "Block 16:\n",
      "  Values: [275 421  48 426 489 136  30 274  10 178]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 275  842  144 1704 2445  816  210 2192   90 1780]\n",
      "  Checksum: 10498\n",
      "\n",
      "Block 17:\n",
      "  Values: [  1 280 447 185 228 135  69 492 199 352]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [   1  560 1341  740 1140  810  483 3936 1791 3520]\n",
      "  Checksum: 14322\n",
      "\n",
      "Block 18:\n",
      "  Values: [  8 276 230 334  96  38 368 261 404 168]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [   8  552  690 1336  480  228 2576 2088 3636 1680]\n",
      "  Checksum: 13274\n",
      "\n",
      "Block 19:\n",
      "  Values: [ 29 437 423  54 284 485  68  32 349  41]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  29  874 1269  216 1420 2910  476  256 3141  410]\n",
      "  Checksum: 11001\n",
      "\n",
      "Block 20:\n",
      "  Values: [ 63 416  55 130 116  76 462 330  37 256]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  63  832  165  520  580  456 3234 2640  333 2560]\n",
      "  Checksum: 11383\n",
      "\n",
      "Block 21:\n",
      "  Values: [390 216 174 180 476 312 265 115  71 218]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 390  432  522  720 2380 1872 1855  920  639 2180]\n",
      "  Checksum: 11910\n",
      "\n",
      "Block 22:\n",
      "  Values: [202 440 385 373 210  89 149  26   7 435]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 202  880 1155 1492 1050  534 1043  208   63 4350]\n",
      "  Checksum: 10977\n",
      "\n",
      "Block 23:\n",
      "  Values: [482 177 157 412  22 194  14 151 233 206]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 482  354  471 1648  110 1164   98 1208 2097 2060]\n",
      "  Checksum: 9692\n",
      "\n",
      "Block 24:\n",
      "  Values: [245 122  94 461 226  97  91  51  33 453]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 245  244  282 1844 1130  582  637  408  297 4530]\n",
      "  Checksum: 10199\n",
      "\n",
      "Block 25:\n",
      "  Values: [ 67  46 322  66 399 487 138  62 211  52]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  67   92  966  264 1995 2922  966  496 1899  520]\n",
      "  Checksum: 10187\n",
      "\n",
      "Block 26:\n",
      "  Values: [269 119 100 442 310 143 301 113 298 478]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 269  238  300 1768 1550  858 2107  904 2682 4780]\n",
      "  Checksum: 15456\n",
      "\n",
      "Block 27:\n",
      "  Values: [272 354   0 249 192  86 172 357 331 300]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 272  708    0  996  960  516 1204 2856 2979 3000]\n",
      "  Checksum: 13491\n",
      "\n",
      "Block 28:\n",
      "  Values: [450 477 163 308 196  47 133 359  64  42]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 450  954  489 1232  980  282  931 2872  576  420]\n",
      "  Checksum: 9186\n",
      "\n",
      "Block 29:\n",
      "  Values: [409 406 238 483 193 311 140 388  56 236]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 409  812  714 1932  965 1866  980 3104  504 2360]\n",
      "  Checksum: 13646\n",
      "\n",
      "Block 30:\n",
      "  Values: [372 110 248  60 181 203 326  90 169 292]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 372  220  744  240  905 1218 2282  720 1521 2920]\n",
      "  Checksum: 11142\n",
      "\n",
      "Block 31:\n",
      "  Values: [479 142   4 124 324 121 131 166 468 365]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 479  284   12  496 1620  726  917 1328 4212 3650]\n",
      "  Checksum: 13724\n",
      "\n",
      "Block 32:\n",
      "  Values: [213  87 353 101 333 114 459  45 338  18]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 213  174 1059  404 1665  684 3213  360 3042  180]\n",
      "  Checksum: 10994\n",
      "\n",
      "Block 33:\n",
      "  Values: [222 343  20 224  12  79 387 251 120 471]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 222  686   60  896   60  474 2709 2008 1080 4710]\n",
      "  Checksum: 12905\n",
      "\n",
      "Block 34:\n",
      "  Values: [ 77 376 327 432 384 321 212 407 266 145]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [  77  752  981 1728 1920 1926 1484 3256 2394 1450]\n",
      "  Checksum: 15968\n",
      "\n",
      "Block 35:\n",
      "  Values: [201 456 260 305 329 420 392 417 190 158]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 201  912  780 1220 1645 2520 2744 3336 1710 1580]\n",
      "  Checksum: 16648\n",
      "\n",
      "Block 36:\n",
      "  Values: [443  83 374 457 125 328 159 147 195 377]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 443  166 1122 1828  625 1968 1113 1176 1755 3770]\n",
      "  Checksum: 13966\n",
      "\n",
      "Block 37:\n",
      "  Values: [367 394 494 304 446  43 262 128 102 449]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 367  788 1482 1216 2230  258 1834 1024  918 4490]\n",
      "  Checksum: 14607\n",
      "\n",
      "Block 38:\n",
      "  Values: [184 469 452 234 362 356 144 291 484 188]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 184  938 1356  936 1810 2136 1008 2328 4356 1880]\n",
      "  Checksum: 16932\n",
      "\n",
      "Block 39:\n",
      "  Values: [414  92 241 306 350 425 281 207 126 302]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 414  184  723 1224 1750 2550 1967 1656 1134 3020]\n",
      "  Checksum: 14622\n",
      "\n",
      "Block 40:\n",
      "  Values: [146 451 498 339 250 344 346 348 496 106]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 146  902 1494 1356 1250 2064 2422 2784 4464 1060]\n",
      "  Checksum: 17942\n",
      "\n",
      "Block 41:\n",
      "  Values: [118 270 433 307 173 252 314 410 490 277]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 118  540 1299 1228  865 1512 2198 3280 4410 2770]\n",
      "  Checksum: 18220\n",
      "\n",
      "Block 42:\n",
      "  Values: [391 264 325 289 160 341 132 337 428 445]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 391  528  975 1156  800 2046  924 2696 3852 4450]\n",
      "  Checksum: 17818\n",
      "\n",
      "Block 43:\n",
      "  Values: [497 187 183 271 396 293 400 360 297 371]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 497  374  549 1084 1980 1758 2800 2880 2673 3710]\n",
      "  Checksum: 18305\n",
      "\n",
      "Block 44:\n",
      "  Values: [491 389 386 288 379 268 472 273 287 448]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 491  778 1158 1152 1895 1608 3304 2184 2583 4480]\n",
      "  Checksum: 19633\n",
      "\n",
      "Block 45:\n",
      "  Values: [176 411 408 242 364  58 467 170  15 240]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 176  822 1224  968 1820  348 3269 1360  135 2400]\n",
      "  Checksum: 12522\n",
      "\n",
      "Block 46:\n",
      "  Values: [316 229 217 109 227 290 460 393 282  34]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 316  458  651  436 1135 1740 3220 3144 2538  340]\n",
      "  Checksum: 13978\n",
      "\n",
      "Block 47:\n",
      "  Values: [220 208 243 139 320 383 244 286 480 431]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 220  416  729  556 1600 2298 1708 2288 4320 4310]\n",
      "  Checksum: 18445\n",
      "\n",
      "Block 48:\n",
      "  Values: [279 198 381 463 366 255 439 401 475 257]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 279  396 1143 1852 1830 1530 3073 3208 4275 2570]\n",
      "  Checksum: 20156\n",
      "\n",
      "Block 49:\n",
      "  Values: [152 235 464 253 231 427 141 186 161 413]\n",
      "  Weights: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "  Weighted values: [ 152  470 1392 1012 1155 2562  987 1488 1449 4130]\n",
      "  Checksum: 14797\n",
      "Values checksums:\n",
      "     correct  learner  agree\n",
      "0       6695     6695   True\n",
      "10     14428    14428   True\n",
      "20     16742    16742   True\n",
      "30      9275     9275   True\n",
      "40     12290    12290   True\n",
      "50     14654    14654   True\n",
      "60      9421     9421   True\n",
      "70     10185    10185   True\n",
      "80     11464    11464   True\n",
      "90     16491    16491   True\n",
      "100    11797    11797   True\n",
      "110    14036    14036   True\n",
      "120    15459    15459   True\n",
      "130     9412     9412   True\n",
      "140    13069    13069   True\n",
      "150    10400    10400   True\n",
      "160    10498    10498   True\n",
      "170    14322    14322   True\n",
      "180    13274    13274   True\n",
      "190    11001    11001   True\n",
      "200    11383    11383   True\n",
      "210    11910    11910   True\n",
      "220    10977    10977   True\n",
      "230     9692     9692   True\n",
      "240    10199    10199   True\n",
      "250    10187    10187   True\n",
      "260    15456    15456   True\n",
      "270    13491    13491   True\n",
      "280     9186     9186   True\n",
      "290    13646    13646   True\n",
      "300    11142    11142   True\n",
      "310    13724    13724   True\n",
      "320    10994    10994   True\n",
      "330    12905    12905   True\n",
      "340    15968    15968   True\n",
      "350    16648    16648   True\n",
      "360    13966    13966   True\n",
      "370    14607    14607   True\n",
      "380    16932    16932   True\n",
      "390    14622    14622   True\n",
      "400    17942    17942   True\n",
      "410    18220    18220   True\n",
      "420    17818    17818   True\n",
      "430    18305    18305   True\n",
      "440    19633    19633   True\n",
      "450    12522    12522   True\n",
      "460    13978    13978   True\n",
      "470    18445    18445   True\n",
      "480    20156    20156   True\n",
      "490    14797    14797   True\n",
      "Passed values check ✅\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def run_v_check(s_test):\n",
    "    print(s_test.iloc[10*0:(0+1)*10].values)\n",
    "    print(np.array(range(1, 11)))\n",
    "    print(s_test.iloc[10*0:(0+1)*10].values * np.array(range(1, 11)))\n",
    "    print(s_test.iloc[10*0:(0+1)*10].values * np.array(range(1, 11)).sum())\n",
    "    \n",
    "    learner_checksums = []\n",
    "    for i in range(50):\n",
    "        block = s_test.iloc[10*i:(i+1)*10].values\n",
    "        weights = np.array(range(1, 11))\n",
    "        weighted_block = block * weights\n",
    "        checksum = weighted_block.sum()\n",
    "    \n",
    "        # Print debugging info\n",
    "        print(f\"\\nBlock {i}:\")\n",
    "        print(f\"  Values: {block}\")\n",
    "        print(f\"  Weights: {weights}\")\n",
    "        print(f\"  Weighted values: {weighted_block}\")\n",
    "        print(f\"  Checksum: {checksum}\")\n",
    "    \n",
    "        #learner_checksums.append(checksum)\n",
    "    \n",
    "    '''print(s_test.iloc[10*i:(i+1)*10].values * np.array(range(1, 11))).sum()\n",
    "                for i in range(50))'''\n",
    "    \"\"\"\n",
    "    Check if the parsed dates appear to be correct and correctly sorted.\n",
    "    The check works by producing some test checksums.\n",
    "    The results of the test are printed and saved to a CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        v_check = pd.DataFrame({\n",
    "            'correct': [\n",
    "                6695, 14428, 16742, 9275, 12290, 14654, 9421, 10185, 11464, 16491,\n",
    "                11797, 14036, 15459, 9412, 13069, 10400, 10498, 14322, 13274, 11001,\n",
    "                11383, 11910, 10977, 9692, 10199, 10187, 15456, 13491, 9186, 13646,\n",
    "                11142, 13724, 10994, 12905, 15968, 16648, 13966, 14607, 16932, 14622,\n",
    "                17942, 18220, 17818, 18305, 19633, 12522, 13978, 18445, 20156, 14797\n",
    "            ],\n",
    "            'learner': [\n",
    "                (s_test.iloc[10*i:(i+1)*10].values * np.array(range(1, 11))).sum()\n",
    "                for i in range(50)\n",
    "            ]\n",
    "        }, index=range(0, 500, 10))\n",
    "\n",
    "        v_check['agree'] = v_check['correct'] == v_check['learner']\n",
    "\n",
    "        print(\"Values checksums:\")\n",
    "        print(v_check)\n",
    "\n",
    "        # Save results to CSV for inspection\n",
    "        v_check.to_csv('value_check_results.csv', index=True)\n",
    "\n",
    "        # Print mismatches only\n",
    "        mismatches = v_check[~v_check['agree']]\n",
    "        if not mismatches.empty:\n",
    "            print(\"\\nMismatches:\")\n",
    "            print(mismatches)\n",
    "        else:\n",
    "            print(\"Passed values check ✅\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed values check ❌\")\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    return\n",
    "run_v_check(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
